{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a26a34e",
   "metadata": {},
   "source": [
    "## Baseline models\n",
    "\n",
    "This notebook defines simple model-free baselines for the ReaLchords dataset and evaluates them\n",
    "using the same offline metrics as the trained model.\n",
    "\n",
    "Baselines:\n",
    "- Global majority-chord predictor.\n",
    "- Last-chord persistence predictor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a056c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/drewtaylor/data\n",
      "Processed data dir: /Users/drewtaylor/data/realchords_data\n",
      "Test examples: 2760\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Locate project root (directory containing pyproject.toml or src/musicagent)\n",
    "project_root = Path.cwd()\n",
    "while project_root != project_root.parent:\n",
    "    if (project_root / \"pyproject.toml\").exists() or (project_root / \"src\" / \"musicagent\").exists():\n",
    "        break\n",
    "    project_root = project_root.parent\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from musicagent.config import DataConfig\n",
    "from musicagent.dataset import MusicAgentDataset, collate_fn\n",
    "from musicagent.eval.metrics import (\n",
    "    chord_length_entropy,\n",
    "    chord_lengths,\n",
    "    note_in_chord_ratio,\n",
    "    onset_interval_emd,\n",
    "    onset_intervals,\n",
    ")\n",
    "\n",
    "# Make data_processed absolute so it works regardless of notebook CWD\n",
    "d_cfg = DataConfig()\n",
    "if not d_cfg.data_processed.is_absolute():\n",
    "    d_cfg.data_processed = project_root / d_cfg.data_processed\n",
    "\n",
    "print(\"Processed data dir:\", d_cfg.data_processed)\n",
    "\n",
    "test_ds = MusicAgentDataset(d_cfg, split=\"test\")\n",
    "print(\"Test examples:\", len(test_ds))\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "id_to_melody = {v: k for k, v in test_ds.vocab_melody.items()}\n",
    "id_to_chord = {v: k for k, v in test_ds.vocab_chord.items()}\n",
    "\n",
    "def decode_tokens(ids, id_to_token):\n",
    "    return [id_to_token.get(int(i), \"<unk>\") for i in ids]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47da62c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference NiC Ratio:         65.31%\n",
      "Reference Chord Length Entropy: 2.296499290802694\n"
     ]
    }
   ],
   "source": [
    "# Compute reference metrics (ground-truth chords) for comparison\n",
    "\n",
    "all_nic_ref = []\n",
    "all_ref_intervals = []\n",
    "all_ref_lengths = []\n",
    "\n",
    "for src, tgt in test_loader:\n",
    "    for i in range(src.size(0)):\n",
    "        mel_ids = src[i].cpu().tolist()\n",
    "        ref_ids = tgt[i].cpu().tolist()\n",
    "\n",
    "        mel_tokens = decode_tokens(mel_ids, id_to_melody)\n",
    "        ref_tokens = decode_tokens(ref_ids, id_to_chord)\n",
    "\n",
    "        all_nic_ref.append(note_in_chord_ratio(mel_tokens, ref_tokens))\n",
    "        all_ref_intervals.extend(onset_intervals(mel_tokens, ref_tokens))\n",
    "        all_ref_lengths.extend(chord_lengths(ref_tokens))\n",
    "\n",
    "avg_nic_ref = sum(all_nic_ref) / len(all_nic_ref) if all_nic_ref else 0.0\n",
    "ref_entropy = chord_length_entropy(all_ref_lengths)\n",
    "\n",
    "print(f\"Reference NiC Ratio:         {avg_nic_ref * 100:.2f}%\")\n",
    "print(\"Reference Chord Length Entropy:\", ref_entropy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf0c69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common non-special chord token: C:4-3/0_hold (count = 25665 )\n"
     ]
    }
   ],
   "source": [
    "# Global majority-chord baseline (excluding special tokens)\n",
    "\n",
    "special_ids = {d_cfg.pad_id, d_cfg.sos_id, d_cfg.eos_id, d_cfg.rest_id}\n",
    "\n",
    "all_chords = []\n",
    "for idx in range(len(test_ds)):\n",
    "    tgt_arr = np.array(test_ds.tgt_data[idx])\n",
    "    # Only count \"real\" chord IDs when choosing the majority chord.\n",
    "    all_chords.extend(int(tid) for tid in tgt_arr.tolist() if int(tid) not in special_ids)\n",
    "\n",
    "chord_counts = Counter(all_chords)\n",
    "most_common_id, most_common_count = chord_counts.most_common(1)[0]\n",
    "most_common_token = id_to_chord.get(int(most_common_id), \"<unk>\")\n",
    "\n",
    "print(\"Most common non-special chord token:\", most_common_token, \"(count =\", most_common_count, \")\")\n",
    "\n",
    "\n",
    "def predict_majority_like_ref(ref_ids, majority_id, eos_id):\n",
    "    \"\"\"Predict the majority chord wherever ref is not EOS; preserve EOS positions.\n",
    "\n",
    "    This baseline deliberately predicts a single, common *real* chord token.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for tid in ref_ids:\n",
    "        tid = int(tid)\n",
    "        if tid == int(eos_id):\n",
    "            result.append(tid)\n",
    "        else:\n",
    "            result.append(int(majority_id))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0debb60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority baseline NiC:         27.46%\n",
      "Majority baseline Onset EMD:    16.318362787500355\n",
      "Majority baseline Chord Ent.:   0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate majority-chord baseline\n",
    "\n",
    "all_nic_major = []\n",
    "all_pred_intervals_major = []\n",
    "all_pred_lengths_major = []\n",
    "\n",
    "for src, tgt in test_loader:\n",
    "    for i in range(src.size(0)):\n",
    "        mel_ids = src[i].cpu().tolist()\n",
    "        ref_ids = tgt[i].cpu().tolist()\n",
    "\n",
    "        pred_ids = predict_majority_like_ref(ref_ids, most_common_id, d_cfg.eos_id)\n",
    "\n",
    "        mel_tokens = decode_tokens(mel_ids, id_to_melody)\n",
    "        pred_tokens = decode_tokens(pred_ids, id_to_chord)\n",
    "\n",
    "        all_nic_major.append(note_in_chord_ratio(mel_tokens, pred_tokens))\n",
    "        all_pred_intervals_major.extend(onset_intervals(mel_tokens, pred_tokens))\n",
    "        all_pred_lengths_major.extend(chord_lengths(pred_tokens))\n",
    "\n",
    "avg_nic_major = sum(all_nic_major) / len(all_nic_major) if all_nic_major else 0.0\n",
    "emd_major = onset_interval_emd(all_pred_intervals_major, all_ref_intervals)\n",
    "entropy_major = chord_length_entropy(all_pred_lengths_major)\n",
    "\n",
    "print(f\"Majority baseline NiC:         {avg_nic_major * 100:.2f}%\")\n",
    "print(\"Majority baseline Onset EMD:   \", emd_major)\n",
    "print(\"Majority baseline Chord Ent.:  \", entropy_major)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a886fef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last-chord baseline NiC:         50.67%\n",
      "Last-chord baseline Onset EMD:    1.6636751333136883\n",
      "Last-chord baseline Chord Ent.:   0.0\n"
     ]
    }
   ],
   "source": [
    "# Last-chord persistence baseline (ignoring special tokens for persistence)\n",
    "\n",
    "\n",
    "def predict_last_chord_persistence(ref_ids, eos_id, special_ids):\n",
    "    \"\"\"Repeat the last seen non-special, non-EOS chord ID; keep EOS/specials where they appear.\n",
    "\n",
    "    If no chord has been seen yet, use the current token as-is.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    last_chord = None\n",
    "    for tid in ref_ids:\n",
    "        tid = int(tid)\n",
    "        if tid == int(eos_id):\n",
    "            # Preserve EOS markers exactly.\n",
    "            result.append(tid)\n",
    "            continue\n",
    "        if tid in special_ids:\n",
    "            # Keep special tokens (pad/rest/sos) but do not update last_chord.\n",
    "            result.append(tid)\n",
    "            continue\n",
    "        # Real chord token\n",
    "        if last_chord is None:\n",
    "            last_chord = tid\n",
    "            result.append(tid)\n",
    "        else:\n",
    "            result.append(last_chord)\n",
    "    return result\n",
    "\n",
    "\n",
    "all_nic_last = []\n",
    "all_pred_intervals_last = []\n",
    "all_pred_lengths_last = []\n",
    "\n",
    "for src, tgt in test_loader:\n",
    "    for i in range(src.size(0)):\n",
    "        mel_ids = src[i].cpu().tolist()\n",
    "        ref_ids = tgt[i].cpu().tolist()\n",
    "\n",
    "        pred_ids = predict_last_chord_persistence(ref_ids, d_cfg.eos_id, special_ids)\n",
    "\n",
    "        mel_tokens = decode_tokens(mel_ids, id_to_melody)\n",
    "        pred_tokens = decode_tokens(pred_ids, id_to_chord)\n",
    "\n",
    "        all_nic_last.append(note_in_chord_ratio(mel_tokens, pred_tokens))\n",
    "        all_pred_intervals_last.extend(onset_intervals(mel_tokens, pred_tokens))\n",
    "        all_pred_lengths_last.extend(chord_lengths(pred_tokens))\n",
    "\n",
    "avg_nic_last = sum(all_nic_last) / len(all_nic_last) if all_nic_last else 0.0\n",
    "emd_last = onset_interval_emd(all_pred_intervals_last, all_ref_intervals)\n",
    "entropy_last = chord_length_entropy(all_pred_lengths_last)\n",
    "\n",
    "print(f\"Last-chord baseline NiC:         {avg_nic_last * 100:.2f}%\")\n",
    "print(\"Last-chord baseline Onset EMD:   \", emd_last)\n",
    "print(\"Last-chord baseline Chord Ent.:  \", entropy_last)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922dc15",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Compare these baselines directly against your trained model metrics from `offline.ipynb`.\n",
    "- Add additional baselines (e.g., simple rule-based harmonic functions, key-aware majority chords).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
