{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drewtaylor/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drewtaylor/data/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%cd ..\n",
    "project_root = Path.cwd()\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from musicagent.config import DataConfig\n",
    "from musicagent.data import OfflineDataset, make_offline_collate_fn\n",
    "from musicagent.eval.metrics import (\n",
    "    chord_length_entropy,\n",
    "    chord_lengths,\n",
    "    chord_silence_counts,\n",
    "    note_in_chord_ratio,\n",
    "    onset_interval_emd,\n",
    "    onset_intervals,\n",
    ")\n",
    "from musicagent.utils import compute_test_set_histograms\n",
    "\n",
    "d_cfg = DataConfig()\n",
    "if not d_cfg.data_processed.is_absolute():\n",
    "    d_cfg.data_processed = project_root / d_cfg.data_processed\n",
    "\n",
    "test_ds = OfflineDataset(d_cfg, split=\"test\")\n",
    "collate_fn = make_offline_collate_fn(pad_id=d_cfg.pad_id)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "mel_id_to_token = test_ds.melody_id_to_token\n",
    "chord_id_to_token = test_ds.chord_id_to_token\n",
    "\n",
    "\n",
    "def decode_melody(ids):\n",
    "    return [mel_id_to_token.get(int(i), \"<unk>\") for i in ids]\n",
    "\n",
    "\n",
    "def decode_chords(ids):\n",
    "    return [chord_id_to_token.get(int(i), \"<unk>\") for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference NiC:                 65.31% (±26.42%)\n",
      "Reference Onset Interval EMD:  0.00 ×10⁻³\n",
      "Reference Chord Length Entropy:2.26\n",
      "Reference Chord Silence Ratio: 3.22%\n",
      "Reference Long Chord Ratio:    0.99%\n",
      "Reference Early Stop Ratio:    0.00%\n"
     ]
    }
   ],
   "source": [
    "# Reference test-set metrics (ground-truth melody/chord pairs)\n",
    "\n",
    "all_nic_ref: list[float] = []\n",
    "all_ref_intervals: list[int] = []\n",
    "all_ref_lengths: list[int] = []\n",
    "\n",
    "# Additional aggregates to mirror offline/online eval metrics\n",
    "total_silent_frames = 0\n",
    "total_melody_frames = 0\n",
    "total_long_chords = 0\n",
    "total_chords = 0\n",
    "early_stop_sequences = 0\n",
    "num_sequences = 0\n",
    "\n",
    "\n",
    "def _ended_early(mel_ids: list[int], chord_ids: list[int]) -> bool:\n",
    "    \"\"\"Return True if the chord sequence ends (EOS) before the melody.\n",
    "\n",
    "    This mirrors the logic used in offline/online evaluation so that we can\n",
    "    verify the dataset itself does not exhibit early stopping.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        eos_idx = chord_ids.index(d_cfg.eos_id)\n",
    "    except ValueError:\n",
    "        # No EOS in chords – treat as not early.\n",
    "        return False\n",
    "\n",
    "    # Find last non-PAD frame in melody.\n",
    "    last_mel_idx = len(mel_ids) - 1\n",
    "    while last_mel_idx >= 0 and mel_ids[last_mel_idx] == d_cfg.pad_id:\n",
    "        last_mel_idx -= 1\n",
    "\n",
    "    if last_mel_idx <= 0:\n",
    "        return False\n",
    "    return eos_idx < last_mel_idx\n",
    "\n",
    "\n",
    "for src, tgt in test_loader:\n",
    "    for i in range(src.size(0)):\n",
    "        mel_ids = src[i].cpu().tolist()\n",
    "        chord_ids = tgt[i].cpu().tolist()\n",
    "\n",
    "        mel_tokens = decode_melody(mel_ids)\n",
    "        chord_tokens = decode_chords(chord_ids)\n",
    "\n",
    "        # NiC (reference upper bound using ground-truth chords)\n",
    "        nic = note_in_chord_ratio(mel_tokens, chord_tokens)\n",
    "        all_nic_ref.append(nic)\n",
    "\n",
    "        # Onset intervals and chord lengths\n",
    "        all_ref_intervals.extend(onset_intervals(mel_tokens, chord_tokens))\n",
    "        lengths = chord_lengths(chord_tokens)\n",
    "        all_ref_lengths.extend(lengths)\n",
    "\n",
    "        # Silence / long-chord statistics (predicted-only metrics in eval,\n",
    "        # but here computed for the reference chords).\n",
    "        silent, total = chord_silence_counts(mel_tokens, chord_tokens)\n",
    "        total_silent_frames += silent\n",
    "        total_melody_frames += total\n",
    "\n",
    "        long_threshold = 32\n",
    "        total_long_chords += sum(1 for L in lengths if L > long_threshold)\n",
    "        total_chords += len(lengths)\n",
    "\n",
    "        # Early-stop check on reference data (should be ~0%).\n",
    "        if _ended_early(mel_ids, chord_ids):\n",
    "            early_stop_sequences += 1\n",
    "\n",
    "        num_sequences += 1\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "avg_nic_ref = float(np.mean(all_nic_ref)) if all_nic_ref else 0.0\n",
    "std_nic_ref = float(np.std(all_nic_ref)) if all_nic_ref else 0.0\n",
    "ref_emd_self = onset_interval_emd(all_ref_intervals, all_ref_intervals)\n",
    "ref_entropy = chord_length_entropy(all_ref_lengths)\n",
    "\n",
    "silence_ratio = (\n",
    "    (total_silent_frames / total_melody_frames) * 100.0 if total_melody_frames > 0 else 0.0\n",
    ")\n",
    "long_chord_ratio = (\n",
    "    (total_long_chords / total_chords) * 100.0 if total_chords > 0 else 0.0\n",
    ")\n",
    "early_stop_ratio = (\n",
    "    (early_stop_sequences / num_sequences) * 100.0 if num_sequences > 0 else 0.0\n",
    ")\n",
    "\n",
    "print(f\"Reference NiC:                 {avg_nic_ref * 100:.2f}% (±{std_nic_ref * 100:.2f}%)\")\n",
    "print(f\"Reference Onset Interval EMD:  {ref_emd_self * 1e3:.2f} ×10⁻³\")\n",
    "print(f\"Reference Chord Length Entropy:{ref_entropy:.2f}\")\n",
    "print(f\"Reference Chord Silence Ratio: {silence_ratio:.2f}%\")\n",
    "print(f\"Reference Long Chord Ratio:    {long_chord_ratio:.2f}%\")\n",
    "print(f\"Reference Early Stop Ratio:    {early_stop_ratio:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
